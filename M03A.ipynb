{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M03A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M03A資料可作為統計通過門架ID對應的**通過量**  \n",
    "可以分析路段的道路服務水準"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "import shutil\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(folder_name):\n",
    "    \"\"\"建立資料夾\"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return os.path.abspath(folder_name)\n",
    "\n",
    "def delete_folders(deletelist):\n",
    "    \"\"\"\n",
    "    刪除資料夾\n",
    "    deletelist(list):需要為皆為路徑的list\n",
    "    \"\"\"\n",
    "    for folder_name in deletelist: \n",
    "        if os.path.exists(folder_name): # 檢查資料夾是否存在\n",
    "            shutil.rmtree(folder_name) # 刪除資料夾及其內容\n",
    "        else:\n",
    "            print(f\"資料夾 '{folder_name}' 不存在。\")\n",
    "\n",
    "def getdatelist(time1, time2):\n",
    "    '''\n",
    "    建立日期清單\n",
    "    time1、time2(str):為%Y-%M-%D格式的日期字串\n",
    "    '''\n",
    "    if time1 > time2:\n",
    "        starttime = time2\n",
    "        endtime = time1\n",
    "    else:\n",
    "        starttime = time1\n",
    "        endtime = time2\n",
    "\n",
    "    date_range = pd.date_range(start=starttime, end=endtime)\n",
    "    datelist = [d.strftime(\"%Y%m%d\") for d in date_range]\n",
    "    return datelist\n",
    "\n",
    "def delete_folders_permanently(deletelist):\n",
    "    \"\"\"\n",
    "    永久刪除資料夾及其內容，不放入資源回收筒\n",
    "    deletelist (list): 需要刪除的資料夾路徑列表\n",
    "    \"\"\"\n",
    "    for item in deletelist:\n",
    "        if os.path.isdir(item):  # 檢查是否為資料夾\n",
    "            try:\n",
    "                shutil.rmtree(item)  # 永久刪除資料夾\n",
    "                print(f\"已永久刪除資料夾： {item}\")\n",
    "            except OSError as e:\n",
    "                print(f\"刪除資料夾 {item} 時發生錯誤： {e}\")\n",
    "        elif os.path.isfile(item):  # 檢查是否為檔案\n",
    "            try:\n",
    "                os.remove(item)  # 永久刪除檔案\n",
    "                print(f\"已永久刪除檔案： {item}\")\n",
    "            except OSError as e:\n",
    "                print(f\"刪除檔案 {item} 時發生錯誤： {e}\")\n",
    "        else:\n",
    "            print(f\"{item} 不是檔案或資料夾。\")\n",
    "\n",
    "def extract_tar_gz(tar_gz_file, extract_path):\n",
    "    try:\n",
    "        with tarfile.open(tar_gz_file, 'r:gz') as tar:\n",
    "            tar.extractall(path=extract_path)\n",
    "    except Exception as e:\n",
    "        print(f\"解壓縮 {tar_gz_file} 失敗：{e}\")\n",
    "\n",
    "def download_and_extract(url, datatype, date, downloadfolder, keep = False):\n",
    "    '''針對高公局交通資料庫的格式進行下載'''\n",
    "    downloadurl = f\"{url}/{datatype}_{date}.tar.gz\"\n",
    "    destfile = os.path.join(downloadfolder, f\"{datatype}_{date}.tar.gz\")\n",
    "\n",
    "    response = requests.get(downloadurl)\n",
    "    with open(destfile, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    extractpath = create_folder(os.path.join(downloadfolder, date))\n",
    "    extract_tar_gz(destfile, extractpath)\n",
    "    if keep == False:\n",
    "        os.remove(destfile)\n",
    "\n",
    "    return extractpath\n",
    "\n",
    "def findfiles(filefolderpath, filetype='.csv'):\n",
    "    \"\"\"\n",
    "    尋找指定路徑下指定類型的檔案，並返回檔案路徑列表。\n",
    "\n",
    "    Args:\n",
    "        filefolderpath (str): 指定的檔案路徑。\n",
    "        filetype (str, optional): 要尋找的檔案類型，預設為 '.csv'。\n",
    "\n",
    "    Returns:\n",
    "        list: 包含所有符合條件的檔案路徑的列表。\n",
    "    \"\"\"\n",
    "\n",
    "    filelist = []  # 建立一個空列表來儲存檔案路徑\n",
    "\n",
    "    # 使用 os.walk 遍歷資料夾及其子資料夾\n",
    "    for root, _, files in os.walk(filefolderpath):\n",
    "        for file in files:\n",
    "            if file.endswith(filetype):  # 檢查檔案是否以指定類型結尾\n",
    "                file_path = os.path.join(root, file)  # 建立完整的檔案路徑\n",
    "                filelist.append(file_path)  # 將檔案路徑添加到列表中\n",
    "\n",
    "    return filelist\n",
    "\n",
    "def combinefile(filelist, datatype='M03A'):\n",
    "    \"\"\"\n",
    "    更有效率地合併多個CSV檔案。\n",
    "\n",
    "    Args:\n",
    "        filelist (list): 包含CSV檔案路徑的列表。\n",
    "        datatype (str, optional): 資料類型，決定欄位名稱。預設為 'M03A'。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 合併後的DataFrame。\n",
    "    \"\"\"\n",
    "\n",
    "    # 使用字典來映射資料類型和欄位名稱，避免重複的 if/elif 判斷\n",
    "    column_mapping = {\n",
    "        'M03A': ['TimeStamp', 'GantryID', 'Direction', 'VehicleType', 'Volume'],\n",
    "        'M04A': ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'TravelTime', 'Volume'],\n",
    "        'M05A': ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'Speed', 'Volume'],\n",
    "        'M06A': ['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd', 'TripInformation'],\n",
    "        'M07A': ['TimeStamp', 'GantryO', 'VehicleType', 'AverageTripLength', 'Volume'],\n",
    "        'M08A': ['TimeStamp', 'GantryO', 'GantryD', 'VehicleType', 'Trips']\n",
    "    }\n",
    "\n",
    "    columns = column_mapping.get(datatype)  # 使用 get() 方法，如果找不到鍵，會返回 None\n",
    "    if columns is None:\n",
    "        raise ValueError(f\"未知的資料類型：{datatype}\")\n",
    "\n",
    "    combineddf = pd.concat(\n",
    "        (pd.read_csv(i, header=None, names=columns) for i in filelist),  # 使用生成器表達式\n",
    "        ignore_index=True  # 避免重複的索引\n",
    "    )\n",
    "\n",
    "    return combineddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "待改進\n",
    "def combinefile(filelist, datatype = 'M03A'):\n",
    "    if datatype == 'M03A':\n",
    "        columns = ['TimeStamp', 'GantryID', 'Direction', 'VehicleType', 'Volume']\n",
    "    elif datatype == 'M04A':\n",
    "        columns = ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'TravelTime', 'Volume']\n",
    "    elif datatype == 'M05A':\n",
    "        columns = ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'Speed', 'Volume']\n",
    "    elif datatype == 'M06A':\n",
    "        columns = ['VehicleType', 'DetectionTimeO', 'GantryO',  'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd', 'TripInformation']\n",
    "    elif datatype == 'M07A':\n",
    "        columns = ['TimeStamp', 'GantryO', 'VehicleType', 'AverageTripLength', 'Volume']\n",
    "    elif datatype == 'M08A':\n",
    "        columns = ['TimeStamp',\t'GantryO', 'GantryD', 'VehicleType', 'Trips']\n",
    "    \n",
    "    combineddf = []\n",
    "    for i in filelist:\n",
    "        df = pd.read_csv(i, header=None)\n",
    "        df.columns = columns\n",
    "        combineddf.append(df)\n",
    "    combineddf = pd.concat(combineddf)\n",
    "\n",
    "    return combineddf\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需要調整的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Step 0: 手動需要調整的參數 =====\n",
    "\n",
    "# 需要調整的項目有2個\n",
    "# 1. 調整需要確認下載的資料型態是什麼\n",
    "datatype = \"M03A\"  # Data type (e.g., M03A, M06A, M05A) \n",
    "\n",
    "# 2. 調整下載的資料區間\n",
    "starttime = \"2024-07-16\"\n",
    "endtime = \"2024-07-19\"\n",
    "datelist = getdatelist(endtime,starttime) # 下載的時間區間清單\n",
    "\n",
    "# 建立後續要處理儲存資料的資料夾位置\n",
    "savelocation = create_folder(os.path.join(os.getcwd(), datatype))\n",
    "rawdatafolder = create_folder(os.path.join(savelocation, '0_rawdata'))\n",
    "mergefolder = create_folder(os.path.join(savelocation, '1_merge'))\n",
    "excelfolder = create_folder(os.path.join(savelocation, '2_excel'))\n",
    "basicurl = \"https://tisvcloud.freeway.gov.tw/history/TDCS/\"\n",
    "url = basicurl + datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_folders([savelocation])\n",
    "\n",
    "# delete_folders_permanently([savelocation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 程式執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 下載並解壓縮\n",
    "date = datelist[0]\n",
    "dowloadfilefolder = download_and_extract(url = url, datatype = datatype, date = date, downloadfolder = rawdatafolder)\n",
    "\n",
    "# 2. 合併\n",
    "filelist = findfiles(filefolderpath=dowloadfilefolder, filetype='.csv')\n",
    "df = combinefile(filelist=filelist, datatype=datatype)\n",
    "mergeoutputfolder = create_folder(os.path.join(mergefolder, date)) # 建立相同日期的資料夾進行處理\n",
    "df.to_csv(os.path.join(mergeoutputfolder, f'{date}.csv') , index = False) # 輸出整併過的csv\n",
    "delete_folders([dowloadfilefolder]) #回頭刪除解壓縮過的資料\n",
    "\n",
    "# 3. 處理\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>GantryID</th>\n",
       "      <th>Direction</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-16 03:55</td>\n",
       "      <td>01F0005N</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-16 03:55</td>\n",
       "      <td>01F0005N</td>\n",
       "      <td>N</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-16 03:55</td>\n",
       "      <td>01F0005N</td>\n",
       "      <td>N</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-16 03:55</td>\n",
       "      <td>01F0005N</td>\n",
       "      <td>N</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-16 03:55</td>\n",
       "      <td>01F0005N</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>2024-07-16 22:50</td>\n",
       "      <td>05FR143N</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>2024-07-16 22:50</td>\n",
       "      <td>05FR143N</td>\n",
       "      <td>N</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>2024-07-16 22:50</td>\n",
       "      <td>05FR143N</td>\n",
       "      <td>N</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>2024-07-16 22:50</td>\n",
       "      <td>05FR143N</td>\n",
       "      <td>N</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>2024-07-16 22:50</td>\n",
       "      <td>05FR143N</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488160 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TimeStamp  GantryID Direction  VehicleType  Volume\n",
       "0     2024-07-16 03:55  01F0005N         N           31      10\n",
       "1     2024-07-16 03:55  01F0005N         N           32      13\n",
       "2     2024-07-16 03:55  01F0005N         N           41       0\n",
       "3     2024-07-16 03:55  01F0005N         N           42       0\n",
       "4     2024-07-16 03:55  01F0005N         N            5       1\n",
       "...                ...       ...       ...          ...     ...\n",
       "1690  2024-07-16 22:50  05FR143N         N           31       4\n",
       "1691  2024-07-16 22:50  05FR143N         N           32       0\n",
       "1692  2024-07-16 22:50  05FR143N         N           41       0\n",
       "1693  2024-07-16 22:50  05FR143N         N           42       0\n",
       "1694  2024-07-16 22:50  05FR143N         N            5       0\n",
       "\n",
       "[488160 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "header must be integer or list of integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilelist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTimeStamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGantryID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDirection\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVehicleType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVolume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1614\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1613\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_file_or_buffer(f, engine)\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1787\u001b[0m, in \u001b[0;36mTextFileReader._clean_options\u001b[0;34m(self, options, engine)\u001b[0m\n\u001b[1;32m   1784\u001b[0m na_values \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mna_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1785\u001b[0m skiprows \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskiprows\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 1787\u001b[0m \u001b[43mvalidate_header_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe value of index_col couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:222\u001b[0m, in \u001b[0;36mvalidate_header_arg\u001b[0;34m(header)\u001b[0m\n\u001b[1;32m    220\u001b[0m header \u001b[38;5;241m=\u001b[39m cast(Sequence, header)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mmap\u001b[39m(is_integer, header)):\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheader must be integer or list of integers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m header):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot specify multi-index header with negative integers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: header must be integer or list of integers"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filelist[0], header=['TimeStamp', 'GantryID', 'Direction', 'VehicleType', 'Volume'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del destfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadurl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "######################## Step 0: Basic Settings ############################\n",
    "location = os.getcwd()\n",
    "data_type = \"M06A\"  # Data type (e.g., M03A, M06A, M05A)\n",
    "savelocation = os.path.join(location, data_type)\n",
    "os.makedirs(savelocation, exist_ok=True)\n",
    "\n",
    "# Subfolder for raw data\n",
    "savelocation_origin = os.path.join(location, data_type, \"0_rawdata\")\n",
    "os.makedirs(savelocation_origin, exist_ok=True)\n",
    "\n",
    "# Subfolder for merged data\n",
    "savelocation_merge = os.path.join(location, data_type, \"1_merge\")\n",
    "os.makedirs(savelocation_merge, exist_ok=True)\n",
    "\n",
    "# Subfolder for Excel files\n",
    "savelocation_excel = os.path.join(location, data_type, \"2_excel\")\n",
    "os.makedirs(savelocation_excel, exist_ok=True)\n",
    "\n",
    "url = \"https://tisvcloud.freeway.gov.tw/history/TDCS/\"\n",
    "urllocation = url + data_type\n",
    "\n",
    "print(f\"Main folder: {savelocation}\")\n",
    "print(f\"Raw data folder: {savelocation_origin}\")\n",
    "print(f\"Merged data folder: {savelocation_merge}\")\n",
    "print(f\"Excel files folder: {savelocation_excel}\")\n",
    "print(f\"Download URL: {urllocation}\")\n",
    "\n",
    "######################## Step 1: Time Range ########################\n",
    "Start_Time = \"2024-08-01\"\n",
    "End_Time = \"2024-08-01\"\n",
    "date_range = pd.date_range(start=Start_Time, end=End_Time)\n",
    "date = [d.strftime(\"%Y%m%d\") for d in date_range]\n",
    "\n",
    "######################## Step 2: Download M06A and Organized ########################\n",
    "\n",
    "# Process to excel\n",
    "def M06A_tohour(df):\n",
    "    df.columns = ['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd']\n",
    "    df = df[df['TripEnd'] == 'Y']\n",
    "    df['DetectionTimeO'] = pd.to_datetime(df['DetectionTimeO'])\n",
    "    df['DataHour'] = df['DetectionTimeO'].dt.hour\n",
    "    df['DataDate'] = df['DetectionTimeO'].dt.date\n",
    "    df_output = df.groupby(['DataDate', 'DataHour','GantryO', 'GantryD', 'VehicleType' ]).size().reset_index(name='VehicleCount')\n",
    "    return df_output\n",
    "\n",
    "\n",
    "for i in range(len(date)):\n",
    "    os.chdir(savelocation_origin)\n",
    "\n",
    "    # Data download\n",
    "    downloadurl = f\"{urllocation}/{data_type}_{date[i]}.tar.gz\"\n",
    "    destfile = f\"{data_type}_{date[i]}.tar.gz\"\n",
    "    print(f\"Downloading {destfile}...\")\n",
    "    response = requests.get(downloadurl)\n",
    "    with open(destfile, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    # Unzip and delete compressed file\n",
    "    print(\"Extracting files...\")\n",
    "    subprocess.run([r\"C:\\Program Files\\7-Zip\\7zG.exe\", \"x\", destfile, f\"-o{savelocation_origin}\"])\n",
    "    subprocess.run([r\"C:\\Program Files\\7-Zip\\7zG.exe\", \"x\", destfile.replace(\".gz\", \"\"), f\"-o{savelocation_origin}\"])\n",
    "    os.remove(destfile)\n",
    "    os.remove(destfile.replace(\".gz\", \"\"))\n",
    "\n",
    "    # Merge hourly data\n",
    "    print(\"Merging hourly data...\")\n",
    "    df = pd.DataFrame(columns=['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd'])\n",
    "    path = os.path.join(savelocation_origin, data_type, date[i])\n",
    "    hour = os.listdir(path)\n",
    "\n",
    "    for j in range(len(hour)):\n",
    "        path2 = os.path.join(path, hour[j])\n",
    "        files = os.listdir(path2)\n",
    "        for k in range(len(files)):\n",
    "            read_path = os.path.join(path2, files[k])\n",
    "            # M06A = pd.read_csv(read_path, header=None, names=['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd','TripInformation'])\n",
    "            M06A = pd.read_csv(\n",
    "                    read_path,\n",
    "                    header=None,\n",
    "                    names=['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd'],\n",
    "                    usecols=[0, 1, 2, 3, 4, 5, 6] \n",
    "                )\n",
    "            df = pd.concat([df, M06A], ignore_index=True)\n",
    "        print(f\"Processing hour {j+1}/{len(hour)}\", end='\\r')\n",
    "\n",
    "    export_path = os.path.join(savelocation_merge, f\"{date[i]}.csv\")\n",
    "    df.to_csv(export_path, index=False)\n",
    "    print(f\"\\nSaved merged data to {export_path}\")\n",
    "\n",
    "\n",
    "    # Organize Hourly counts\n",
    "    print(\"Organizing vehicle types...\")\n",
    "    df_hour = M06A_tohour(df)\n",
    "\n",
    "    # Save to Excel\n",
    "    export_path = os.path.join(savelocation_excel, f\"{date[i]}.xlsx\")\n",
    "    df_hour.to_excel(export_path, index=False)\n",
    "    print(f\"Saved Excel file to {export_path}\")\n",
    "\n",
    "    print(f\"Completed processing for date: {date[i]}\\n\")\n",
    "\n",
    "print(\"All processing completed.\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
