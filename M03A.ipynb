{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M03A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M03A資料可作為統計通過門架ID對應的**通過量**  \n",
    "可以分析路段的道路服務水準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(folder_name):\n",
    "    \"\"\"建立資料夾\"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return os.path.abspath(folder_name)\n",
    "\n",
    "def delete_folders(deletelist):\n",
    "    \"\"\"\n",
    "    刪除資料夾\n",
    "    deletelist(list):需要為皆為路徑的list\n",
    "    \"\"\"\n",
    "    for folder_name in deletelist: \n",
    "        if os.path.exists(folder_name): # 檢查資料夾是否存在\n",
    "            shutil.rmtree(folder_name) # 刪除資料夾及其內容\n",
    "        else:\n",
    "            print(f\"資料夾 '{folder_name}' 不存在。\")\n",
    "\n",
    "def getdatelist(time1, time2):\n",
    "    '''\n",
    "    建立日期清單\n",
    "    time1、time2(str):為%Y-%M-%D格式的日期字串\n",
    "    '''\n",
    "    if time1 > time2:\n",
    "        starttime = time2\n",
    "        endtime = time1\n",
    "    else:\n",
    "        starttime = time1\n",
    "        endtime = time2\n",
    "\n",
    "    date_range = pd.date_range(start=starttime, end=endtime)\n",
    "    datelist = [d.strftime(\"%Y%m%d\") for d in date_range]\n",
    "    return datelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Step 0: 手動需要調整的參數 =====\n",
    "\n",
    "# 需要調整的項目有2個\n",
    "# 1. 調整需要確認下載的資料型態是什麼\n",
    "datatype = \"M03A\"  # Data type (e.g., M03A, M06A, M05A) \n",
    "\n",
    "# 2. 調整下載的資料區間\n",
    "starttime = \"2024-07-16\"\n",
    "endtime = \"2024-07-19\"\n",
    "datelist = getdatelist(endtime,starttime) # 下載的時間區間清單\n",
    "\n",
    "# 建立後續要處理儲存資料的資料夾位置\n",
    "savelocation = create_folder(os.path.join(os.getcwd(), datatype))\n",
    "rawdatafolder = create_folder(os.path.join(savelocation, '0_rawdata'))\n",
    "mergefolder = create_folder(os.path.join(savelocation, '1_merge'))\n",
    "excelfolder = create_folder(os.path.join(savelocation, '2_excel'))\n",
    "basicurl = \"https://tisvcloud.freeway.gov.tw/history/TDCS/\"\n",
    "url = basicurl + datatype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_folders([savelocation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadurl = f\"{url}/{datatype}_{datelist[0]}.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadurl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "######################## Step 0: Basic Settings ############################\n",
    "location = os.getcwd()\n",
    "data_type = \"M06A\"  # Data type (e.g., M03A, M06A, M05A)\n",
    "savelocation = os.path.join(location, data_type)\n",
    "os.makedirs(savelocation, exist_ok=True)\n",
    "\n",
    "# Subfolder for raw data\n",
    "savelocation_origin = os.path.join(location, data_type, \"0_rawdata\")\n",
    "os.makedirs(savelocation_origin, exist_ok=True)\n",
    "\n",
    "# Subfolder for merged data\n",
    "savelocation_merge = os.path.join(location, data_type, \"1_merge\")\n",
    "os.makedirs(savelocation_merge, exist_ok=True)\n",
    "\n",
    "# Subfolder for Excel files\n",
    "savelocation_excel = os.path.join(location, data_type, \"2_excel\")\n",
    "os.makedirs(savelocation_excel, exist_ok=True)\n",
    "\n",
    "url = \"https://tisvcloud.freeway.gov.tw/history/TDCS/\"\n",
    "urllocation = url + data_type\n",
    "\n",
    "print(f\"Main folder: {savelocation}\")\n",
    "print(f\"Raw data folder: {savelocation_origin}\")\n",
    "print(f\"Merged data folder: {savelocation_merge}\")\n",
    "print(f\"Excel files folder: {savelocation_excel}\")\n",
    "print(f\"Download URL: {urllocation}\")\n",
    "\n",
    "######################## Step 1: Time Range ########################\n",
    "Start_Time = \"2024-08-01\"\n",
    "End_Time = \"2024-08-01\"\n",
    "date_range = pd.date_range(start=Start_Time, end=End_Time)\n",
    "date = [d.strftime(\"%Y%m%d\") for d in date_range]\n",
    "\n",
    "######################## Step 2: Download M06A and Organized ########################\n",
    "\n",
    "# Process to excel\n",
    "def M06A_tohour(df):\n",
    "    df.columns = ['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd']\n",
    "    df = df[df['TripEnd'] == 'Y']\n",
    "    df['DetectionTimeO'] = pd.to_datetime(df['DetectionTimeO'])\n",
    "    df['DataHour'] = df['DetectionTimeO'].dt.hour\n",
    "    df['DataDate'] = df['DetectionTimeO'].dt.date\n",
    "    df_output = df.groupby(['DataDate', 'DataHour','GantryO', 'GantryD', 'VehicleType' ]).size().reset_index(name='VehicleCount')\n",
    "    return df_output\n",
    "\n",
    "\n",
    "for i in range(len(date)):\n",
    "    os.chdir(savelocation_origin)\n",
    "\n",
    "    # Data download\n",
    "    downloadurl = f\"{urllocation}/{data_type}_{date[i]}.tar.gz\"\n",
    "    destfile = f\"{data_type}_{date[i]}.tar.gz\"\n",
    "    print(f\"Downloading {destfile}...\")\n",
    "    response = requests.get(downloadurl)\n",
    "    with open(destfile, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    # Unzip and delete compressed file\n",
    "    print(\"Extracting files...\")\n",
    "    subprocess.run([r\"C:\\Program Files\\7-Zip\\7zG.exe\", \"x\", destfile, f\"-o{savelocation_origin}\"])\n",
    "    subprocess.run([r\"C:\\Program Files\\7-Zip\\7zG.exe\", \"x\", destfile.replace(\".gz\", \"\"), f\"-o{savelocation_origin}\"])\n",
    "    os.remove(destfile)\n",
    "    os.remove(destfile.replace(\".gz\", \"\"))\n",
    "\n",
    "    # Merge hourly data\n",
    "    print(\"Merging hourly data...\")\n",
    "    df = pd.DataFrame(columns=['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd'])\n",
    "    path = os.path.join(savelocation_origin, data_type, date[i])\n",
    "    hour = os.listdir(path)\n",
    "\n",
    "    for j in range(len(hour)):\n",
    "        path2 = os.path.join(path, hour[j])\n",
    "        files = os.listdir(path2)\n",
    "        for k in range(len(files)):\n",
    "            read_path = os.path.join(path2, files[k])\n",
    "            # M06A = pd.read_csv(read_path, header=None, names=['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd','TripInformation'])\n",
    "            M06A = pd.read_csv(\n",
    "                    read_path,\n",
    "                    header=None,\n",
    "                    names=['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd'],\n",
    "                    usecols=[0, 1, 2, 3, 4, 5, 6] \n",
    "                )\n",
    "            df = pd.concat([df, M06A], ignore_index=True)\n",
    "        print(f\"Processing hour {j+1}/{len(hour)}\", end='\\r')\n",
    "\n",
    "    export_path = os.path.join(savelocation_merge, f\"{date[i]}.csv\")\n",
    "    df.to_csv(export_path, index=False)\n",
    "    print(f\"\\nSaved merged data to {export_path}\")\n",
    "\n",
    "\n",
    "    # Organize Hourly counts\n",
    "    print(\"Organizing vehicle types...\")\n",
    "    df_hour = M06A_tohour(df)\n",
    "\n",
    "    # Save to Excel\n",
    "    export_path = os.path.join(savelocation_excel, f\"{date[i]}.xlsx\")\n",
    "    df_hour.to_excel(export_path, index=False)\n",
    "    print(f\"Saved Excel file to {export_path}\")\n",
    "\n",
    "    print(f\"Completed processing for date: {date[i]}\\n\")\n",
    "\n",
    "print(\"All processing completed.\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
