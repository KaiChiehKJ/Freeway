{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "import shutil\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def create_folder(folder_name):\n",
    "    \"\"\"建立資料夾\"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return os.path.abspath(folder_name)\n",
    "\n",
    "def delete_folders(deletelist):\n",
    "    \"\"\"\n",
    "    刪除資料夾\n",
    "    deletelist(list):需要為皆為路徑的list\n",
    "    \"\"\"\n",
    "    for folder_name in deletelist: \n",
    "        if os.path.exists(folder_name): # 檢查資料夾是否存在\n",
    "            shutil.rmtree(folder_name) # 刪除資料夾及其內容\n",
    "        else:\n",
    "            print(f\"資料夾 '{folder_name}' 不存在。\")\n",
    "\n",
    "def getdatelist(time1, time2):\n",
    "    '''\n",
    "    建立日期清單\n",
    "    time1、time2(str):為%Y-%M-%D格式的日期字串\n",
    "    '''\n",
    "    if time1 > time2:\n",
    "        starttime = time2\n",
    "        endtime = time1\n",
    "    else:\n",
    "        starttime = time1\n",
    "        endtime = time2\n",
    "\n",
    "    date_range = pd.date_range(start=starttime, end=endtime)\n",
    "    datelist = [d.strftime(\"%Y%m%d\") for d in date_range]\n",
    "    return datelist\n",
    "\n",
    "def freewaydatafolder(datatype):\n",
    "    savelocation = create_folder(os.path.join(os.getcwd(), datatype))\n",
    "    rawdatafolder = create_folder(os.path.join(savelocation, '0_rawdata'))\n",
    "    mergefolder = create_folder(os.path.join(savelocation, '1_merge'))\n",
    "    excelfolder = create_folder(os.path.join(savelocation, '2_excel'))\n",
    "    return rawdatafolder, mergefolder, excelfolder\n",
    "\n",
    "def delete_folders_permanently(deletelist):\n",
    "    \"\"\"\n",
    "    永久刪除資料夾及其內容，不放入資源回收筒\n",
    "    deletelist (list): 需要刪除的資料夾路徑列表\n",
    "    \"\"\"\n",
    "    for item in deletelist:\n",
    "        if os.path.isdir(item):  # 檢查是否為資料夾\n",
    "            try:\n",
    "                shutil.rmtree(item)  # 永久刪除資料夾\n",
    "                print(f\"已永久刪除資料夾： {item}\")\n",
    "            except OSError as e:\n",
    "                print(f\"刪除資料夾 {item} 時發生錯誤： {e}\")\n",
    "        elif os.path.isfile(item):  # 檢查是否為檔案\n",
    "            try:\n",
    "                os.remove(item)  # 永久刪除檔案\n",
    "                print(f\"已永久刪除檔案： {item}\")\n",
    "            except OSError as e:\n",
    "                print(f\"刪除檔案 {item} 時發生錯誤： {e}\")\n",
    "        else:\n",
    "            print(f\"{item} 不是檔案或資料夾。\")\n",
    "\n",
    "def download_etag(etagurl, etagdownloadpath):\n",
    "    \"\"\"\n",
    "    下載指定網址的 XML 檔案到指定位置。\n",
    "\n",
    "    Args:\n",
    "        etagurl (str): 要下載的 XML 檔案網址。\n",
    "        etagdownloadpath (str): 檔案下載後的儲存路徑（包含檔案名稱）。\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(etagurl, stream=True)\n",
    "        response.raise_for_status()  # 檢查 HTTP 狀態碼，如有錯誤則拋出異常\n",
    "\n",
    "        with open(etagdownloadpath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"下載時發生錯誤：{e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤：{e}\")\n",
    "\n",
    "def read_xml(xml_file_path):\n",
    "    \"\"\"\n",
    "    讀取並解析 XML 檔案。\n",
    "\n",
    "    Args:\n",
    "        xml_file_path (str): XML 檔案路徑。\n",
    "\n",
    "    Returns:\n",
    "        ElementTree.Element: XML 文件的根節點。\n",
    "        None: 如果解析失敗。\n",
    "    \"\"\"\n",
    "    # try:\n",
    "    #     tree = ET.parse(xml_file_path)\n",
    "    #     root = tree.getroot()\n",
    "    #     return root\n",
    "    try:\n",
    "        with open(xml_file_path, 'r', encoding='utf-8') as f:  # 指定編碼\n",
    "            xml_content = f.read()\n",
    "        return xml_content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"檔案未找到：{xml_file_path}\")\n",
    "        return None\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"解析 XML 檔案時發生錯誤：{e}\")\n",
    "        return None\n",
    "\n",
    "def etag_xml_to_dataframe(xml_content):\n",
    "    \"\"\"\n",
    "    將 XML 內容轉換為 Pandas DataFrame。\n",
    "\n",
    "    Args:\n",
    "        xml_content (str): XML 內容字串。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 轉換後的 DataFrame。\n",
    "        None: 如果解析失敗。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root = ET.fromstring(xml_content)  # 從字串解析 XML\n",
    "\n",
    "        data = []\n",
    "        for etag in root.findall('.//{http://traffic.transportdata.tw/standard/traffic/schema/}ETag'):\n",
    "            etag_data = {}\n",
    "            for element in etag:\n",
    "                tag_name = element.tag.split('}')[-1]  # 去除命名空間\n",
    "                if tag_name == 'RoadSection':  # 處理 RoadSection\n",
    "                    for section_element in element:\n",
    "                        etag_data[section_element.tag] = section_element.text\n",
    "                else:\n",
    "                    etag_data[tag_name] = element.text\n",
    "            data.append(etag_data)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.columns = ['ETagGantryID','LinkID', 'LocationType', 'PositionLon', 'PositionLat', 'RoadID', 'RoadName', 'RoadClass', 'RoadDirection', 'Start','End', 'LocationMile']\n",
    "        return df\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"解析 XML 內容時發生錯誤：{e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤：{e}\")\n",
    "        return None\n",
    "\n",
    "def etag_getdf():\n",
    "    etagfolder = create_folder(os.path.join(os.getcwd(), 'ETag'))\n",
    "    etagurl = 'https://tisvcloud.freeway.gov.tw/history/motc20/ETag.xml'\n",
    "    etagdownloadpath = os.path.join(etagfolder, 'ETag.xml')\n",
    "    download_etag(etagurl=etagurl, etagdownloadpath=etagdownloadpath)\n",
    "    etagxml = read_xml(etagdownloadpath)\n",
    "    etag = etag_xml_to_dataframe(etagxml)\n",
    "\n",
    "    etag.to_excel(os.path.join(etagfolder,'Etag.xlsx'), index = False, sheet_name='ETag')\n",
    "    return etag\n",
    "\n",
    "def extract_tar_gz(tar_gz_file, extract_path):\n",
    "    try:\n",
    "        with tarfile.open(tar_gz_file, 'r:gz') as tar:\n",
    "            tar.extractall(path=extract_path)\n",
    "    except Exception as e:\n",
    "        print(f\"解壓縮 {tar_gz_file} 失敗：{e}\")\n",
    "\n",
    "def download_and_extract(url, datatype, date, downloadfolder, keep = False):\n",
    "    '''針對高公局交通資料庫的格式進行下載'''\n",
    "    downloadurl = f\"{url}/{datatype}_{date}.tar.gz\"\n",
    "    destfile = os.path.join(downloadfolder, f\"{datatype}_{date}.tar.gz\")\n",
    "\n",
    "    response = requests.get(downloadurl)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(destfile, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        extractpath = create_folder(os.path.join(downloadfolder, date))\n",
    "        extract_tar_gz(destfile, extractpath)\n",
    "        if keep == False:\n",
    "            os.remove(destfile)\n",
    "    else:\n",
    "        extractpath = create_folder(os.path.join(downloadfolder, date))\n",
    "        hourlist = [f\"{i:02d}\" for i in range(24)]\n",
    "        if datatype == 'M06A':\n",
    "            for hour in hourlist:\n",
    "                downloadurl = f\"{url}/{date}/{hour}/TDCS_{datatype}_{date}_{hour}0000.csv\"\n",
    "                destfile = os.path.join(extractpath, f\"TDCS_{datatype}_{date}_{hour}0000.csv\")\n",
    "                response = requests.get(downloadurl, stream=True) # 發送 GET 請求下載檔案\n",
    "                if response.status_code == 200:\n",
    "                    with open(destfile, 'wb') as file:\n",
    "                        file.write(response.content)  # 直接寫入整個回應內容\n",
    "                else:\n",
    "                    print(f\"下載失敗: {downloadurl}, 狀態碼: {response.status_code}\")\n",
    "\n",
    "        else :\n",
    "            for hour in hourlist:\n",
    "                minlist = [f\"{i:02d}\" for i in range(0, 60, 5)]\n",
    "                for minute in minlist:\n",
    "                    downloadurl = f\"{url}/{date}/{hour}/TDCS_{datatype}_{date}_{hour}{minute}00.csv\"\n",
    "                    destfile = os.path.join(extractpath, f\"TDCS_{datatype}_{date}_{hour}{minute}00.csv\")\n",
    "\n",
    "                    response = requests.get(downloadurl, stream=True) # 發送 GET 請求下載檔案\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        with open(destfile, 'wb') as file:\n",
    "                            file.write(response.content)  # 直接寫入整個回應內容\n",
    "                    else:\n",
    "                        print(f\"下載失敗: {downloadurl}, 狀態碼: {response.status_code}\")\n",
    "\n",
    "    return extractpath\n",
    "\n",
    "def findfiles(filefolderpath, filetype='.csv'):\n",
    "    \"\"\"\n",
    "    尋找指定路徑下指定類型的檔案，並返回檔案路徑列表。\n",
    "\n",
    "    Args:\n",
    "        filefolderpath (str): 指定的檔案路徑。\n",
    "        filetype (str, optional): 要尋找的檔案類型，預設為 '.csv'。\n",
    "\n",
    "    Returns:\n",
    "        list: 包含所有符合條件的檔案路徑的列表。\n",
    "    \"\"\"\n",
    "\n",
    "    filelist = []  # 建立一個空列表來儲存檔案路徑\n",
    "\n",
    "    # 使用 os.walk 遍歷資料夾及其子資料夾\n",
    "    for root, _, files in os.walk(filefolderpath):\n",
    "        for file in files:\n",
    "            if file.endswith(filetype):  # 檢查檔案是否以指定類型結尾\n",
    "                file_path = os.path.join(root, file)  # 建立完整的檔案路徑\n",
    "                filelist.append(file_path)  # 將檔案路徑添加到列表中\n",
    "\n",
    "    return filelist\n",
    "\n",
    "def combinefile(filelist, datatype='M03A'):\n",
    "    \"\"\"\n",
    "    更有效率地合併多個CSV檔案。\n",
    "\n",
    "    Args:\n",
    "        filelist (list): 包含CSV檔案路徑的列表。\n",
    "        datatype (str, optional): 資料類型，決定欄位名稱。預設為 'M03A'。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 合併後的DataFrame。\n",
    "    \"\"\"\n",
    "\n",
    "    # 使用字典來映射資料類型和欄位名稱，避免重複的 if/elif 判斷\n",
    "    column_mapping = {\n",
    "        'M03A': ['TimeStamp', 'GantryID', 'Direction', 'VehicleType', 'Volume'],\n",
    "        'M04A': ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'TravelTime', 'Volume'],\n",
    "        'M05A': ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'Speed', 'Volume'],\n",
    "        'M06A': ['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd', 'TripInformation'],\n",
    "        'M07A': ['TimeStamp', 'GantryO', 'VehicleType', 'AverageTripLength', 'Volume'],\n",
    "        'M08A': ['TimeStamp', 'GantryO', 'GantryD', 'VehicleType', 'Trips']\n",
    "    }\n",
    "\n",
    "    columns = column_mapping.get(datatype)  # 使用 get() 方法，如果找不到鍵，會返回 None\n",
    "    if columns is None:\n",
    "        raise ValueError(f\"未知的資料類型：{datatype}\")\n",
    "\n",
    "    combineddf = pd.concat(\n",
    "        (pd.read_csv(i, header=None, names=columns) for i in filelist),  # 使用生成器表達式\n",
    "        ignore_index=True  # 避免重複的索引\n",
    "    )\n",
    "\n",
    "    return combineddf\n",
    "\n",
    "def THI_M03A(df):\n",
    "    df = df.pivot(index=['TimeStamp', 'GantryID', 'Direction'], columns='VehicleType', values='Volume').reset_index()\n",
    "    df = df.rename(columns = {\n",
    "        5 : 'Vol_Trail',\n",
    "        31 : 'Vol_Car',\n",
    "        32 : 'Vol_Truck',\n",
    "        41 : 'Vol_TourBus',\n",
    "        42 : 'Vol_BTruck'\n",
    "    })\n",
    "    df = df.reindex(columns = ['TimeStamp', 'GantryID', 'Direction', 'Vol_Trail', 'Vol_Car', 'Vol_Truck', 'Vol_TourBus', 'Vol_BTruck'])\n",
    "\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
    "\n",
    "    df['Date'] = df['TimeStamp'].dt.date\n",
    "    df['Hour'] = df['TimeStamp'].dt.hour\n",
    "\n",
    "    df = df.groupby(['Date','Hour','GantryID','Direction']).agg({\n",
    "            'Vol_Trail':'sum',\n",
    "            'Vol_Car':'sum', \n",
    "            'Vol_Truck':'sum',\n",
    "            'Vol_TourBus':'sum',\n",
    "            'Vol_BTruck':'sum'}).reset_index()\n",
    "    return df\n",
    "\n",
    "def THI_M05A(df, weighted = False):\n",
    "    \n",
    "    # 將每5分鐘的資料，轉為分時資料\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
    "    df['Date'] = df['TimeStamp'].dt.date\n",
    "    df['Hour'] = df['TimeStamp'].dt.hour\n",
    "\n",
    "    df = df[df['Volume']!=0] # 需要避開Volume 為0的資料\n",
    "\n",
    "    if weighted == True:\n",
    "        df['Speed_time_volume'] = df['Speed'] * df['Volume']\n",
    "        df = df.groupby(['Date', 'Hour', 'GantryFrom', 'GantryTo', 'VehicleType']).agg({'Speed_time_volume':'sum', 'Volume':'sum'}).reset_index()\n",
    "        df['Speed'] = df['Speed_time_volume'] / df['Volume']\n",
    "    else :\n",
    "        df = df.groupby(['Date', 'Hour', 'GantryFrom', 'GantryTo', 'VehicleType']).agg({'Speed':'mean'}).reset_index()\n",
    "    \n",
    "    \n",
    "    df['Speed'] = df['Speed'].round(3)\n",
    "    df = df.pivot(index=['Date', 'Hour', 'GantryFrom', 'GantryTo'], columns='VehicleType', values='Speed').reset_index()\n",
    "    df = df.rename(columns = {\n",
    "        5 : 'Speed_Trail',\n",
    "        31 : 'Speed_Car',\n",
    "        32 : 'Speed_Truck',\n",
    "        41 : 'Speed_TourBus',\n",
    "        42 : 'Speed_BTruck'\n",
    "    })\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.reindex(columns = ['Date', 'Hour', 'GantryFrom', 'GantryTo', 'Speed_Trail', 'Speed_Car', 'Speed_Truck', 'Speed_TourBus', 'Speed_BTruck'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def THI_M06A(df, hour = True):\n",
    "    df['DetectionTimeO'] = pd.to_datetime(df['DetectionTimeO'])\n",
    "    df['DetectionTimeD'] = pd.to_datetime(df['DetectionTimeD'])\n",
    "\n",
    "    df['Date'] = df['DetectionTimeO'].dt.date\n",
    "    if hour == True:\n",
    "        df['HourO'] = df['DetectionTimeO'].dt.hour\n",
    "        df['HourD'] = df['DetectionTimeD'].dt.hour\n",
    "        df = df.groupby(['Date','HourO', 'GantryO', 'HourD', 'GantryD', 'VehicleType']).size().reset_index(name='Volume')\n",
    "\n",
    "    df = df.groupby(['Date', 'GantryO', 'GantryD','VehicleType']).size().reset_index(name='Volume')\n",
    "\n",
    "    return df \n",
    "\n",
    "def THI_M08A(df, hour = True):\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
    "\n",
    "    df['Date'] = df['TimeStamp'].dt.date\n",
    "    df['Hour'] = df['TimeStamp'].dt.hour\n",
    "    if hour == True:\n",
    "        df = df.groupby(['Date', 'Hour', 'GantryO', 'GantryD', 'VehicleType']).size().reset_index(name='Volume')\n",
    "    df = df.groupby(['Date', 'GantryO', 'GantryD','VehicleType']).size().reset_index(name='Volume')\n",
    "    return df \n",
    "\n",
    "def THI_process(df, datatype, weighted = False, hour = True):\n",
    "    if datatype == 'M03A':\n",
    "        df = THI_M03A(df)\n",
    "    elif datatype == 'M05A':\n",
    "        df = THI_M05A(df, weighted = weighted)\n",
    "    elif datatype == 'M06A':\n",
    "        df = THI_M06A(df, hour = False)\n",
    "    elif datatype == 'M08A':\n",
    "        df = THI_M08A(df, hour = True)\n",
    "    return df\n",
    "\n",
    "def M03A_Tableau_combined(folder , etag):\n",
    "    allfiles = findfiles(filefolderpath=folder, filetype='.xlsx')\n",
    "    combineddf = pd.concat(\n",
    "        (pd.read_excel(i) for i in allfiles),  # 使用生成器表達式\n",
    "        ignore_index=True  # 避免重複的索引\n",
    "    )\n",
    "\n",
    "    combineddf['Day'] = combineddf[\"Date\"].dt.day_name() #生成星期幾\n",
    "\n",
    "    combineddf = pd.merge(combineddf,etag[['ETagGantryID', 'RoadName','Start', 'End']].rename(columns = {'ETagGantryID':'GantryID'}) , on = 'GantryID')\n",
    "    combineddf['RoadSection'] = combineddf['Start'] + '-' + combineddf['End']\n",
    "\n",
    "    outputfolder = create_folder(os.path.join(folder, '..', '3_TableauData'))\n",
    "    combineddf.to_csv(os.path.join(outputfolder, 'M03A.csv'), index=False)\n",
    "\n",
    "def freeway(datatype, datelist, Tableau = False, etag = None, hour = True, keep = False):\n",
    "    rawdatafolder, mergefolder, excelfolder = freewaydatafolder(datatype=datatype)\n",
    "    url = \"https://tisvcloud.freeway.gov.tw/history/TDCS/\" + datatype\n",
    "\n",
    "    for date in datelist :\n",
    "        # 1. 下載並解壓縮\n",
    "        dowloadfilefolder = download_and_extract(url = url, datatype = datatype, date = date, downloadfolder = rawdatafolder, keep = False)\n",
    "\n",
    "        # 2. 合併\n",
    "        filelist = findfiles(filefolderpath=dowloadfilefolder, filetype='.csv')\n",
    "        df = combinefile(filelist=filelist, datatype=datatype)\n",
    "        mergeoutputfolder = create_folder(os.path.join(mergefolder, date)) # 建立相同日期的資料夾進行處理\n",
    "        df.to_csv(os.path.join(mergeoutputfolder, f'{date}.csv') , index = False) # 輸出整併過的csv\n",
    "        delete_folders([dowloadfilefolder]) #回頭刪除解壓縮過的資料\n",
    "\n",
    "        # # 3. 處理\n",
    "        df = THI_process(df, datatype=datatype)\n",
    "        df.to_excel(os.path.join(excelfolder, f'{date}.xlsx'), index = False, sheet_name = date)\n",
    "    \n",
    "    if Tableau == True:\n",
    "        if datatype == 'M03A':\n",
    "            M03A_Tableau_combined(folder=excelfolder, etag = etag)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ===== Step 0: 手動需要調整的參數 =====\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# freeway(datatype = 'M03A', datelist = datelist, keep=False, Tableau = True, etag = etag) \u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# freeway(datatype = 'M05A', datelist = datelist)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# freeway(datatype = 'M06A', datelist = datelist, hour = True) # 計算OD:如果只是要全日的OD，就可以把\"hour = True\" 改為 \"hour = False\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# freeway(datatype = 'M08A', datelist = datelist)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''主要會用freeway這個函數進行三個步驟 (1) 下載 (2) 整併當日資料 (3) 處理\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m請根據需要調整datatype(str)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m3. M06A : 計算通過兩個門架之間的OD數量\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     17\u001b[0m etag \u001b[38;5;241m=\u001b[39m etag_getdf()\n\u001b[0;32m---> 18\u001b[0m \u001b[43mfreeway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mM06A\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatelist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatelist\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 392\u001b[0m, in \u001b[0;36mfreeway\u001b[0;34m(datatype, datelist, Tableau, etag, hour, keep)\u001b[0m\n\u001b[1;32m    388\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tisvcloud.freeway.gov.tw/history/TDCS/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m datatype\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m datelist :\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# 1. 下載並解壓縮\u001b[39;00m\n\u001b[0;32m--> 392\u001b[0m     dowloadfilefolder \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownloadfolder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrawdatafolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;66;03m# 2. 合併\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     filelist \u001b[38;5;241m=\u001b[39m findfiles(filefolderpath\u001b[38;5;241m=\u001b[39mdowloadfilefolder, filetype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 202\u001b[0m, in \u001b[0;36mdownload_and_extract\u001b[0;34m(url, datatype, date, downloadfolder, keep)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(destfile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m--> 202\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m)  \u001b[38;5;66;03m# 直接寫入整個回應內容\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m下載失敗: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownloadurl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 狀態碼: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 調整下載的資料區間\n",
    "starttime = \"2025-01-24\"\n",
    "endtime = \"2025-02-4\"\n",
    "datelist = getdatelist(endtime,starttime) # 下載的時間區間清單\n",
    "\n",
    "# ===== Step 1: 選擇需要執行的程式碼 ====\n",
    "\n",
    "def main():\n",
    "    '''主要會用freeway這個函數進行三個步驟 (1) 下載 (2) 整併當日資料 (3) 處理\n",
    "    請根據需要調整datatype(str)\n",
    "\n",
    "    1. M03A : 主要計算主要路段通過門架的通過量\n",
    "    2. M05A : 計算通過兩個門架間的速率\n",
    "    3. M06A : 計算通過兩個門架之間的OD數量\n",
    "    '''\n",
    "\n",
    "    etag = etag_getdf()\n",
    "    freeway(datatype = 'M06A', datelist = datelist) \n",
    "    # freeway(datatype = 'M03A', datelist = datelist, keep=False, Tableau = True, etag = etag) \n",
    "    # freeway(datatype = 'M05A', datelist = datelist)\n",
    "    # freeway(datatype = 'M06A', datelist = datelist, hour = True) # 計算OD:如果只是要全日的OD，就可以把\"hour = True\" 改為 \"hour = False\"\n",
    "    # freeway(datatype = 'M08A', datelist = datelist)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整下載的資料區間\n",
    "starttime = \"2023-01-20\"\n",
    "endtime = \"2024-02-4\"\n",
    "datelist = getdatelist(endtime,starttime) # 下載的時間區間清單\n",
    "\n",
    "# ===== Step 1: 選擇需要執行的程式碼 ====\n",
    "\n",
    "def main():\n",
    "    '''主要會用freeway這個函數進行三個步驟 (1) 下載 (2) 整併當日資料 (3) 處理\n",
    "    請根據需要調整datatype(str)\n",
    "\n",
    "    1. M03A : 主要計算主要路段通過門架的通過量\n",
    "    2. M05A : 計算通過兩個門架間的速率\n",
    "    3. M06A : 計算通過兩個門架之間的OD數量\n",
    "    '''\n",
    "\n",
    "    etag = etag_getdf()\n",
    "    freeway(datatype = 'M03A', datelist = datelist) \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangkaijie/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "import shutil\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def create_folder(folder_name):\n",
    "    \"\"\"建立資料夾\"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return os.path.abspath(folder_name)\n",
    "\n",
    "def delete_folders(deletelist):\n",
    "    \"\"\"\n",
    "    刪除資料夾\n",
    "    deletelist(list):需要為皆為路徑的list\n",
    "    \"\"\"\n",
    "    for folder_name in deletelist: \n",
    "        if os.path.exists(folder_name): # 檢查資料夾是否存在\n",
    "            shutil.rmtree(folder_name) # 刪除資料夾及其內容\n",
    "        else:\n",
    "            print(f\"資料夾 '{folder_name}' 不存在。\")\n",
    "\n",
    "def getdatelist(time1, time2):\n",
    "    '''\n",
    "    建立日期清單\n",
    "    time1、time2(str):為%Y-%M-%D格式的日期字串\n",
    "    '''\n",
    "    if time1 > time2:\n",
    "        starttime = time2\n",
    "        endtime = time1\n",
    "    else:\n",
    "        starttime = time1\n",
    "        endtime = time2\n",
    "\n",
    "    date_range = pd.date_range(start=starttime, end=endtime)\n",
    "    datelist = [d.strftime(\"%Y%m%d\") for d in date_range]\n",
    "    return datelist\n",
    "\n",
    "def freewaydatafolder(datatype):\n",
    "    savelocation = create_folder(os.path.join(os.getcwd(), datatype))\n",
    "    rawdatafolder = create_folder(os.path.join(savelocation, '0_rawdata'))\n",
    "    mergefolder = create_folder(os.path.join(savelocation, '1_merge'))\n",
    "    excelfolder = create_folder(os.path.join(savelocation, '2_excel'))\n",
    "    return rawdatafolder, mergefolder, excelfolder\n",
    "\n",
    "def delete_folders_permanently(deletelist):\n",
    "    \"\"\"\n",
    "    永久刪除資料夾及其內容，不放入資源回收筒\n",
    "    deletelist (list): 需要刪除的資料夾路徑列表\n",
    "    \"\"\"\n",
    "    for item in deletelist:\n",
    "        if os.path.isdir(item):  # 檢查是否為資料夾\n",
    "            try:\n",
    "                shutil.rmtree(item)  # 永久刪除資料夾\n",
    "                print(f\"已永久刪除資料夾： {item}\")\n",
    "            except OSError as e:\n",
    "                print(f\"刪除資料夾 {item} 時發生錯誤： {e}\")\n",
    "        elif os.path.isfile(item):  # 檢查是否為檔案\n",
    "            try:\n",
    "                os.remove(item)  # 永久刪除檔案\n",
    "                print(f\"已永久刪除檔案： {item}\")\n",
    "            except OSError as e:\n",
    "                print(f\"刪除檔案 {item} 時發生錯誤： {e}\")\n",
    "        else:\n",
    "            print(f\"{item} 不是檔案或資料夾。\")\n",
    "\n",
    "def download_etag(etagurl, etagdownloadpath):\n",
    "    \"\"\"\n",
    "    下載指定網址的 XML 檔案到指定位置。\n",
    "\n",
    "    Args:\n",
    "        etagurl (str): 要下載的 XML 檔案網址。\n",
    "        etagdownloadpath (str): 檔案下載後的儲存路徑（包含檔案名稱）。\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(etagurl, stream=True)\n",
    "        response.raise_for_status()  # 檢查 HTTP 狀態碼，如有錯誤則拋出異常\n",
    "\n",
    "        with open(etagdownloadpath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"下載時發生錯誤：{e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤：{e}\")\n",
    "\n",
    "def read_xml(xml_file_path):\n",
    "    \"\"\"\n",
    "    讀取並解析 XML 檔案。\n",
    "\n",
    "    Args:\n",
    "        xml_file_path (str): XML 檔案路徑。\n",
    "\n",
    "    Returns:\n",
    "        ElementTree.Element: XML 文件的根節點。\n",
    "        None: 如果解析失敗。\n",
    "    \"\"\"\n",
    "    # try:\n",
    "    #     tree = ET.parse(xml_file_path)\n",
    "    #     root = tree.getroot()\n",
    "    #     return root\n",
    "    try:\n",
    "        with open(xml_file_path, 'r', encoding='utf-8') as f:  # 指定編碼\n",
    "            xml_content = f.read()\n",
    "        return xml_content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"檔案未找到：{xml_file_path}\")\n",
    "        return None\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"解析 XML 檔案時發生錯誤：{e}\")\n",
    "        return None\n",
    "\n",
    "def etag_xml_to_dataframe(xml_content):\n",
    "    \"\"\"\n",
    "    將 XML 內容轉換為 Pandas DataFrame。\n",
    "\n",
    "    Args:\n",
    "        xml_content (str): XML 內容字串。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 轉換後的 DataFrame。\n",
    "        None: 如果解析失敗。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root = ET.fromstring(xml_content)  # 從字串解析 XML\n",
    "\n",
    "        data = []\n",
    "        for etag in root.findall('.//{http://traffic.transportdata.tw/standard/traffic/schema/}ETag'):\n",
    "            etag_data = {}\n",
    "            for element in etag:\n",
    "                tag_name = element.tag.split('}')[-1]  # 去除命名空間\n",
    "                if tag_name == 'RoadSection':  # 處理 RoadSection\n",
    "                    for section_element in element:\n",
    "                        etag_data[section_element.tag] = section_element.text\n",
    "                else:\n",
    "                    etag_data[tag_name] = element.text\n",
    "            data.append(etag_data)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.columns = ['ETagGantryID','LinkID', 'LocationType', 'PositionLon', 'PositionLat', 'RoadID', 'RoadName', 'RoadClass', 'RoadDirection', 'Start','End', 'LocationMile']\n",
    "        return df\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"解析 XML 內容時發生錯誤：{e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤：{e}\")\n",
    "        return None\n",
    "\n",
    "def etag_getdf():\n",
    "    etagfolder = create_folder(os.path.join(os.getcwd(), 'ETag'))\n",
    "    etagurl = 'https://tisvcloud.freeway.gov.tw/history/motc20/ETag.xml'\n",
    "    etagdownloadpath = os.path.join(etagfolder, 'ETag.xml')\n",
    "    download_etag(etagurl=etagurl, etagdownloadpath=etagdownloadpath)\n",
    "    etagxml = read_xml(etagdownloadpath)\n",
    "    etag = etag_xml_to_dataframe(etagxml)\n",
    "\n",
    "    etag.to_excel(os.path.join(etagfolder,'Etag.xlsx'), index = False)\n",
    "    return etag\n",
    "\n",
    "def extract_tar_gz(tar_gz_file, extract_path):\n",
    "    try:\n",
    "        with tarfile.open(tar_gz_file, 'r:gz') as tar:\n",
    "            tar.extractall(path=extract_path)\n",
    "    except Exception as e:\n",
    "        print(f\"解壓縮 {tar_gz_file} 失敗：{e}\")\n",
    "\n",
    "def download_and_extract(url, datatype, date, downloadfolder, keep = False):\n",
    "    '''針對高公局交通資料庫的格式進行下載'''\n",
    "    downloadurl = f\"{url}/{datatype}_{date}.tar.gz\"\n",
    "    destfile = os.path.join(downloadfolder, f\"{datatype}_{date}.tar.gz\")\n",
    "\n",
    "    response = requests.get(downloadurl)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(destfile, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        extractpath = create_folder(os.path.join(downloadfolder, date))\n",
    "        extract_tar_gz(destfile, extractpath)\n",
    "        if keep == False:\n",
    "            os.remove(destfile)\n",
    "    else:\n",
    "        hourlist = [f\"{i:02d}\" for i in range(0, 60, 5)]\n",
    "        if datatype == 'M06A':\n",
    "            for hour in hourlist:\n",
    "                downloadurl = f\"{url}/{date}/{hour}/TDCS_{datatype}_{date}_{hour}0000.csv\"\n",
    "                downloaddatefolder = create_folder(os.path.join(downloadfolder,date))\n",
    "                destfile = os.path.join(downloaddatefolder, f\"TDCS_{datatype}_{date}_{hour}0000.csv\")\n",
    "\n",
    "                response = requests.get(downloadurl, stream=True) # 發送 GET 請求下載檔案\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    with open(destfile, 'wb') as file:\n",
    "                        file.write(response.content)  # 直接寫入整個回應內容\n",
    "                else:\n",
    "                    print(f\"下載失敗: {downloadurl}, 狀態碼: {response.status_code}\")\n",
    "\n",
    "        else :\n",
    "            for hour in hourlist:\n",
    "                downloadurl = f\"{url}/{date}/{hour}/TDCS_{datatype}_{date}_{hour}{min}00.csv\"\n",
    "                downloaddatefolder = create_folder(os.path.join(downloadfolder,date))\n",
    "                destfile = os.path.join(downloaddatefolder, f\"TDCS_{datatype}_{date}_{hour}{min}00.csv\")\n",
    "\n",
    "                response = requests.get(downloadurl, stream=True) # 發送 GET 請求下載檔案\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    with open(destfile, 'wb') as file:\n",
    "                        file.write(response.content)  # 直接寫入整個回應內容\n",
    "                else:\n",
    "                    print(f\"下載失敗: {downloadurl}, 狀態碼: {response.status_code}\")\n",
    "\n",
    "    return extractpath\n",
    "\n",
    "def findfiles(filefolderpath, filetype='.csv'):\n",
    "    \"\"\"\n",
    "    尋找指定路徑下指定類型的檔案，並返回檔案路徑列表。\n",
    "\n",
    "    Args:\n",
    "        filefolderpath (str): 指定的檔案路徑。\n",
    "        filetype (str, optional): 要尋找的檔案類型，預設為 '.csv'。\n",
    "\n",
    "    Returns:\n",
    "        list: 包含所有符合條件的檔案路徑的列表。\n",
    "    \"\"\"\n",
    "\n",
    "    filelist = []  # 建立一個空列表來儲存檔案路徑\n",
    "\n",
    "    # 使用 os.walk 遍歷資料夾及其子資料夾\n",
    "    for root, _, files in os.walk(filefolderpath):\n",
    "        for file in files:\n",
    "            if file.endswith(filetype):  # 檢查檔案是否以指定類型結尾\n",
    "                file_path = os.path.join(root, file)  # 建立完整的檔案路徑\n",
    "                filelist.append(file_path)  # 將檔案路徑添加到列表中\n",
    "\n",
    "    return filelist\n",
    "\n",
    "def combinefile(filelist, datatype='M03A'):\n",
    "    \"\"\"\n",
    "    更有效率地合併多個CSV檔案。\n",
    "\n",
    "    Args:\n",
    "        filelist (list): 包含CSV檔案路徑的列表。\n",
    "        datatype (str, optional): 資料類型，決定欄位名稱。預設為 'M03A'。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 合併後的DataFrame。\n",
    "    \"\"\"\n",
    "\n",
    "    # 使用字典來映射資料類型和欄位名稱，避免重複的 if/elif 判斷\n",
    "    column_mapping = {\n",
    "        'M03A': ['TimeStamp', 'GantryID', 'Direction', 'VehicleType', 'Volume'],\n",
    "        'M04A': ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'TravelTime', 'Volume'],\n",
    "        'M05A': ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'Speed', 'Volume'],\n",
    "        'M06A': ['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd', 'TripInformation'],\n",
    "        'M07A': ['TimeStamp', 'GantryO', 'VehicleType', 'AverageTripLength', 'Volume'],\n",
    "        'M08A': ['TimeStamp', 'GantryO', 'GantryD', 'VehicleType', 'Trips']\n",
    "    }\n",
    "\n",
    "    columns = column_mapping.get(datatype)  # 使用 get() 方法，如果找不到鍵，會返回 None\n",
    "    if columns is None:\n",
    "        raise ValueError(f\"未知的資料類型：{datatype}\")\n",
    "\n",
    "    combineddf = pd.concat(\n",
    "        (pd.read_csv(i, header=None, names=columns) for i in filelist),  # 使用生成器表達式\n",
    "        ignore_index=True  # 避免重複的索引\n",
    "    )\n",
    "\n",
    "    return combineddf\n",
    "\n",
    "def THI_M03A(df):\n",
    "    df = df.pivot(index=['TimeStamp', 'GantryID', 'Direction'], columns='VehicleType', values='Volume').reset_index()\n",
    "    df = df.rename(columns = {\n",
    "        5 : 'Vol_Trail',\n",
    "        31 : 'Vol_Car',\n",
    "        32 : 'Vol_Truck',\n",
    "        41 : 'Vol_TourBus',\n",
    "        42 : 'Vol_BTruck'\n",
    "    })\n",
    "    df = df.reindex(columns = ['TimeStamp', 'GantryID', 'Direction', 'Vol_Trail', 'Vol_Car', 'Vol_Truck', 'Vol_TourBus', 'Vol_BTruck'])\n",
    "\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
    "\n",
    "    df['Date'] = df['TimeStamp'].dt.date\n",
    "    df['Hour'] = df['TimeStamp'].dt.hour\n",
    "\n",
    "    df = df.groupby(['Date','Hour','GantryID','Direction']).agg({\n",
    "            'Vol_Trail':'sum',\n",
    "            'Vol_Car':'sum', \n",
    "            'Vol_Truck':'sum',\n",
    "            'Vol_TourBus':'sum',\n",
    "            'Vol_BTruck':'sum'}).reset_index()\n",
    "    return df\n",
    "\n",
    "def THI_M05A(df, weighted = False):\n",
    "    \n",
    "    # 將每5分鐘的資料，轉為分時資料\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
    "    df['Date'] = df['TimeStamp'].dt.date\n",
    "    df['Hour'] = df['TimeStamp'].dt.hour\n",
    "\n",
    "    df = df[df['Volume']!=0] # 需要避開Volume 為0的資料\n",
    "\n",
    "    if weighted == True:\n",
    "        df['Speed_time_volume'] = df['Speed'] * df['Volume']\n",
    "        df = df.groupby(['Date', 'Hour', 'GantryFrom', 'GantryTo', 'VehicleType']).agg({'Speed_time_volume':'sum', 'Volume':'sum'}).reset_index()\n",
    "        df['Speed'] = df['Speed_time_volume'] / df['Volume']\n",
    "    else :\n",
    "        df = df.groupby(['Date', 'Hour', 'GantryFrom', 'GantryTo', 'VehicleType']).agg({'Speed':'mean'}).reset_index()\n",
    "    \n",
    "    \n",
    "    df['Speed'] = df['Speed'].round(3)\n",
    "    df = df.pivot(index=['Date', 'Hour', 'GantryFrom', 'GantryTo'], columns='VehicleType', values='Speed').reset_index()\n",
    "    df = df.rename(columns = {\n",
    "        5 : 'Speed_Trail',\n",
    "        31 : 'Speed_Car',\n",
    "        32 : 'Speed_Truck',\n",
    "        41 : 'Speed_TourBus',\n",
    "        42 : 'Speed_BTruck'\n",
    "    })\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.reindex(columns = ['Date', 'Hour', 'GantryFrom', 'GantryTo', 'Speed_Trail', 'Speed_Car', 'Speed_Truck', 'Speed_TourBus', 'Speed_BTruck'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def THI_M06A(df, hour = True):\n",
    "    df['DetectionTimeO'] = pd.to_datetime(df['DetectionTimeO'])\n",
    "    df['DetectionTimeD'] = pd.to_datetime(df['DetectionTimeD'])\n",
    "\n",
    "    df['Date'] = df['DetectionTimeO'].dt.date\n",
    "    if hour == True:\n",
    "        df['HourO'] = df['DetectionTimeO'].dt.hour\n",
    "        df['HourD'] = df['DetectionTimeD'].dt.hour\n",
    "        df = df.groupby(['Date','HourO', 'GantryO', 'HourD', 'GantryD', 'VehicleType']).size().reset_index(name='Volume')\n",
    "\n",
    "    df = df.groupby(['Date', 'GantryO', 'GantryD','VehicleType']).size().reset_index(name='Volume')\n",
    "\n",
    "    return df \n",
    "\n",
    "def THI_process(df, datatype, weighted = False, hour = True):\n",
    "    if datatype == 'M03A':\n",
    "        df = THI_M03A(df)\n",
    "    elif datatype == 'M05A':\n",
    "        df = THI_M05A(df, weighted = weighted)\n",
    "    elif datatype == 'M06A':\n",
    "        df = THI_M06A(df, hour = hour)\n",
    "    return df\n",
    "\n",
    "def M03A_Tableau_combined(folder , etag):\n",
    "    allfiles = findfiles(filefolderpath=folder, filetype='.xlsx')\n",
    "    combineddf = pd.concat(\n",
    "        (pd.read_excel(i) for i in allfiles),  # 使用生成器表達式\n",
    "        ignore_index=True  # 避免重複的索引\n",
    "    )\n",
    "\n",
    "    combineddf['Day'] = combineddf[\"Date\"].dt.day_name() #生成星期幾\n",
    "\n",
    "    combineddf = pd.merge(combineddf,etag[['ETagGantryID', 'RoadName','Start', 'End']].rename(columns = {'ETagGantryID':'GantryID'}) , on = 'GantryID')\n",
    "    combineddf['RoadSection'] = combineddf['Start'] + '-' + combineddf['End']\n",
    "\n",
    "    outputfolder = create_folder(os.path.join(folder, '..', '3_TableauData'))\n",
    "    combineddf.to_csv(os.path.join(outputfolder, 'M03A.csv'), index=False)\n",
    "\n",
    "def freeway(datatype, datelist, Tableau = False, etag = None, hour = True, keep = False):\n",
    "    rawdatafolder, mergefolder, excelfolder = freewaydatafolder(datatype=datatype)\n",
    "    url = \"https://tisvcloud.freeway.gov.tw/history/TDCS/\" + datatype\n",
    "\n",
    "    for date in datelist :\n",
    "        # 1. 下載並解壓縮\n",
    "        dowloadfilefolder = download_and_extract(url = url, datatype = datatype, date = date, downloadfolder = rawdatafolder, keep = False)\n",
    "\n",
    "        # 2. 合併\n",
    "        filelist = findfiles(filefolderpath=dowloadfilefolder, filetype='.csv')\n",
    "        df = combinefile(filelist=filelist, datatype=datatype)\n",
    "        mergeoutputfolder = create_folder(os.path.join(mergefolder, date)) # 建立相同日期的資料夾進行處理\n",
    "        df.to_csv(os.path.join(mergeoutputfolder, f'{date}.csv') , index = False) # 輸出整併過的csv\n",
    "        delete_folders([dowloadfilefolder]) #回頭刪除解壓縮過的資料\n",
    "\n",
    "        # # 3. 處理\n",
    "        df = THI_process(df, datatype=datatype)\n",
    "        df.to_excel(os.path.join(excelfolder, f'{date}.xlsx'), index = False, sheet_name = date)\n",
    "    \n",
    "    if Tableau == True:\n",
    "        if datatype == 'M03A':\n",
    "            M03A_Tableau_combined(folder=excelfolder, etag = etag)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ===== Step 0: 手動需要調整的參數 =====\n",
    "# 調整下載的資料區間\n",
    "starttime = \"2024-01-24\"\n",
    "endtime = \"2024-02-09\"\n",
    "datelist = getdatelist(endtime,starttime) # 下載的時間區間清單\n",
    "\n",
    "# ===== Step 1: 選擇需要執行的程式碼 ====\n",
    "\n",
    "def main():\n",
    "    '''主要會用freeway這個函數進行三個步驟 (1) 下載 (2) 整併當日資料 (3) 處理\n",
    "    請根據需要調整datatype(str)\n",
    "\n",
    "    1. M03A : 主要計算主要路段通過門架的通過量\n",
    "    2. M05A : 計算通過兩個門架間的速率\n",
    "    3. M06A : 計算通過兩個門架之間的OD數量\n",
    "    '''\n",
    "\n",
    "    etag = etag_getdf()\n",
    "    \n",
    "    freeway(datatype = 'M03A', datelist = datelist, keep=False, Tableau = True, etag = etag) \n",
    "    # freeway(datatype = 'M05A', datelist = datelist)\n",
    "    # freeway(datatype = 'M06A', datelist = datelist, hour = True) # 計算OD:如果只是要全日的OD，就可以把\"hour = True\" 改為 \"hour = False\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
